https://lh3.googleusercontent.com/jQD_IBf0TWGY7qphGx3i04G_T5uddH5XmPcwLuQwXyNwwKfXP2SeP88VUAAnWRx8uDeN2nYn5_O3uhp1WsY=s1500

Search Engine Diagram

Introducing the Web Crawler

A web crawler is a program that collects content from the web. A web crawler finds web pages by starting from a seed page and following links to find other pages, and following links from the other pages it finds, and continuing to follow links until it has found many web pages.

Here is the process that a web crawler follows:

Start from one preselected page. We call the starting page the "seed" page.
Extract all the links on that page. (This is the part we will work on in this unit and Unit 2.)
Follow each of those links to find new pages.
Extract all the links from all of the new pages found.
Follow each of those links to find new pages.
Extract all the links from all of the new pages found.
...
This keeps going as long as there are new pages to find, or until it is stopped.
https://www.udacity.com/wiki/cs101/unit-1#!#quiz-20-answer
